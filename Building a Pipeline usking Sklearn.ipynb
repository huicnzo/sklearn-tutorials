{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a pipeline in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a typical pipeline consists of a\n",
    "\n",
    "pre-processing step that transforms or\n",
    "\n",
    "imputes(filling up missing values) the data and the final predictor\n",
    "\n",
    "that predicts target values so\n",
    "\n",
    "transformers and estimators that is the\n",
    "\n",
    "predictors can be combined together into\n",
    "\n",
    "a single unifying object it is a\n",
    "\n",
    "pipeline , so pipeline is combining\n",
    "\n",
    "different transformers and estimators to\n",
    "\n",
    "automate machine learning workflows as\n",
    "\n",
    "it sequentially applies \n",
    "\n",
    "a list of transforms and a final\n",
    "\n",
    "estimate . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #for feature scaling\n",
    "from sklearn.linear_model import LogisticRegression #for classification\n",
    "from sklearn.model_selection import train_test_split  \n",
    "#train_test_split is a function in Sklearn model selection for splitting data arrays into two subsets: for training data and for testing data.\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('minmax', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X_train , X_test , y_train , y_test = train_test_split(iris.data,iris.target,test_size = 0.2 , random_state = 42 )\n",
    "#here test_size = 0.2 means test set is 20 % of entire sample .\n",
    "pipe_lr = Pipeline([('minmax',MinMaxScaler()),('lr',LogisticRegression())])\n",
    "#we just created our pipeline\n",
    "pipe_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.score(X_test ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
